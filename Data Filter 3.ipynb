{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from nltk.corpus import framenet as fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_names_list = [\n",
    "'Abandonment',\n",
    "'Abundance',\n",
    "'Abusing',\n",
    "'Accompaniment',\n",
    "'Accomplishment',\n",
    "'Accoutrements',\n",
    "'Accuracy',\n",
    "'Achieving_first',\n",
    "'Activity',\n",
    "'Activity_done_state',\n",
    "'Activity_finish',\n",
    "'Activity_ongoing',\n",
    "'Activity_pause',\n",
    "'Activity_prepare',\n",
    "'Activity_resume',\n",
    "'Activity_stop',\n",
    "'Actually_occurring_entity',\n",
    "'Addiction',\n",
    "'Adducing',\n",
    "'Adopt_selection',\n",
    "'Affirm_or_deny',\n",
    "'Age',\n",
    "'Aggregate',\n",
    "'Aging',\n",
    "'Agree_or_refuse_to_act',\n",
    "'Agriculture',\n",
    "'Alliance',\n",
    "'Alternatives',\n",
    "'Ambient_temperature',\n",
    "'Ammunition',\n",
    "'Amounting_to',\n",
    "'Animals',\n",
    "'Annoyance',\n",
    "'Appellations',\n",
    "'Apply_heat',\n",
    "'Appointing',\n",
    "'Architectural_part',\n",
    "'Armor',\n",
    "'Arraignment',\n",
    "'Arrest',\n",
    "'Arriving',\n",
    "'Arson',\n",
    "'Artifact',\n",
    "'Artificiality',\n",
    "'Assemble',\n",
    "'Assessing',\n",
    "'Assigned_location',\n",
    "'Assistance',\n",
    "'Asymmetric_reciprocality',\n",
    "'Atonement',\n",
    "'Attaching',\n",
    "'Attack',\n",
    "'Attempt',\n",
    "'Attempt_action_scenario',\n",
    "'Attempt_means',\n",
    "'Attempt_suasion',\n",
    "'Attempting_and_resolving_scenario',\n",
    "'Attending',\n",
    "'Attention',\n",
    "'Attitude_description',\n",
    "'Authority',\n",
    "'Avoiding',\n",
    "'Awareness',\n",
    "'Awareness_situation',\n",
    "'Awareness_status',\n",
    "'Bail_decision',\n",
    "'Basis_for_attribute',\n",
    "'Be_in_agreement_on_action',\n",
    "'Be_in_agreement_on_assessment',\n",
    "'Be_on_alert',\n",
    "'Be_subset_of',\n",
    "'Bearing_arms',\n",
    "'Becoming',\n",
    "'Becoming_a_member',\n",
    "'Becoming_aware',\n",
    "'Becoming_silent',\n",
    "'Becoming_visible',\n",
    "'Behind_the_scenes',\n",
    "'Being_active',\n",
    "'Being_at_risk',\n",
    "'Being_attached',\n",
    "'Being_born',\n",
    "'Being_employed',\n",
    "'Being_in_captivity',\n",
    "'Being_in_effect',\n",
    "'Being_in_operation',\n",
    "'Being_incarcerated',\n",
    "'Being_located',\n",
    "'Being_named',\n",
    "'Being_necessary',\n",
    "'Being_questionable',\n",
    "'Being_up_to_it',\n",
    "'Besieging',\n",
    "'Beyond_compare',\n",
    "'Billing',\n",
    "'Biological_area',\n",
    "'Biological_entity',\n",
    "'Biological_urge',\n",
    "'Board_vehicle',\n",
    "'Body_decoration',\n",
    "'Body_description_holistic',\n",
    "'Body_description_part',\n",
    "'Body_mark',\n",
    "'Body_movement',\n",
    "'Body_parts',\n",
    "'Bond_maturation',\n",
    "'Borrowing',\n",
    "'Bragging',\n",
    "'Breaking_apart',\n",
    "'Breaking_out_captive',\n",
    "'Breathing',\n",
    "'Bringing',\n",
    "'Building',\n",
    "'Buildings',\n",
    "'Bungling',\n",
    "'Burying',\n",
    "'Business_closure',\n",
    "'Businesses',\n",
    "'Cache',\n",
    "'Calendric_unit',\n",
    "'Candidness',\n",
    "'Capability',\n",
    "'Capacity',\n",
    "'Cardinal_numbers',\n",
    "'Carry_goods',\n",
    "'Causation',\n",
    "'Causation_scenario',\n",
    "'Cause_bodily_experience',\n",
    "'Cause_change',\n",
    "'Cause_change_of_position_on_a_scale',\n",
    "'Cause_change_of_strength',\n",
    "'Cause_emotion',\n",
    "'Cause_expansion',\n",
    "'Cause_harm',\n",
    "'Cause_impact',\n",
    "'Cause_motion',\n",
    "'Cause_proliferation_in_number',\n",
    "'Cause_to_be_dry',\n",
    "'Cause_to_continue',\n",
    "'Cause_to_end',\n",
    "'Cause_to_experience',\n",
    "'Cause_to_fragment',\n",
    "'Cause_to_land',\n",
    "'Cause_to_perceive',\n",
    "'Cause_to_resume',\n",
    "'Cause_to_start',\n",
    "'Ceasing_to_be',\n",
    "'Certainty',\n",
    "'Change_accessibility',\n",
    "'Change_direction',\n",
    "'Change_event_time',\n",
    "'Change_of_leadership',\n",
    "'Change_of_phase',\n",
    "'Change_operational_state',\n",
    "'Change_tool',\n",
    "'Chaos',\n",
    "'Chatting',\n",
    "'Chemical-sense_description',\n",
    "'Choosing',\n",
    "'Citing',\n",
    "'Claim_ownership',\n",
    "'Clemency',\n",
    "'Closure',\n",
    "'Clothing',\n",
    "'Cogitation',\n",
    "'Coincidence',\n",
    "'Collaboration',\n",
    "'Color',\n",
    "'Come_down_with',\n",
    "'Come_into_effect',\n",
    "'Come_together',\n",
    "'Coming_to_believe',\n",
    "'Coming_up_with',\n",
    "'Commerce_buy',\n",
    "'Commerce_collect',\n",
    "'Commerce_goods-transfer',\n",
    "'Commerce_money-transfer',\n",
    "'Commerce_pay',\n",
    "'Commerce_scenario',\n",
    "'Commerce_sell',\n",
    "'Commitment',\n",
    "'Committing_crime',\n",
    "'Communication',\n",
    "'Communication_manner',\n",
    "'Communication_means',\n",
    "'Communication_noise',\n",
    "'Commutation',\n",
    "'Competition',\n",
    "'Complaining',\n",
    "'Compliance',\n",
    "'Concessive',\n",
    "'Conduct',\n",
    "'Conferring_benefit',\n",
    "'Connecting_architecture',\n",
    "'Connectors',\n",
    "'Conquering',\n",
    "'Container_focused_removing',\n",
    "'Containers',\n",
    "'Containing',\n",
    "'Contrition',\n",
    "'Control',\n",
    "'Controller_object',\n",
    "'Convey_importance',\n",
    "'Convoy',\n",
    "'Cooking_creation',\n",
    "'Corporal_punishment',\n",
    "'Correctness',\n",
    "'Cotheme',\n",
    "'Counterattack',\n",
    "'Court_examination',\n",
    "'Craft',\n",
    "'Create_physical_artwork',\n",
    "'Create_representation',\n",
    "'Creating',\n",
    "'Criminal_investigation',\n",
    "'Cure',\n",
    "'Custom',\n",
    "'Cutting',\n",
    "'Damaging',\n",
    "'Daring',\n",
    "'Dead_or_alive',\n",
    "'Death',\n",
    "'Defending',\n",
    "'Degree',\n",
    "'Delimitation_of_diversity',\n",
    "'Delivery',\n",
    "'Deny_or_grant_permission',\n",
    "'Departing',\n",
    "'Deserving',\n",
    "'Desirability',\n",
    "'Desirable_event',\n",
    "'Desiring',\n",
    "'Destiny',\n",
    "'Detaching',\n",
    "'Differentiation',\n",
    "'Difficulty',\n",
    "'Dimension',\n",
    "'Direction',\n",
    "'Directional_locative_relation',\n",
    "'Disaster_scenario',\n",
    "'Discussion',\n",
    "'Disembarking',\n",
    "'Disgraceful_situation',\n",
    "'Distant_operated_IED',\n",
    "'Distinctiveness',\n",
    "'Distributed_position',\n",
    "'Diversity',\n",
    "'Documents',\n",
    "'Dodging',\n",
    "'Domain',\n",
    "'Dominate_competitor',\n",
    "'Dominate_situation',\n",
    "'Dunking',\n",
    "'Duplication',\n",
    "'Duration_description',\n",
    "'Dynamism',\n",
    "'Earnings_and_losses',\n",
    "'Economy',\n",
    "'Education_teaching',\n",
    "'Electricity',\n",
    "'Emanating',\n",
    "'Emitting',\n",
    "'Emotion_active',\n",
    "'Emotion_directed',\n",
    "'Emotion_heat',\n",
    "'Emotions_by_stimulus',\n",
    "'Emotions_of_mental_activity',\n",
    "'Emphasizing',\n",
    "'Employer_scenario',\n",
    "'Employing',\n",
    "'Emptying',\n",
    "'Entity',\n",
    "'Entourage',\n",
    "'Erasing',\n",
    "'Evaluative_comparison',\n",
    "'Eventive_affecting',\n",
    "'Evidence',\n",
    "'Examination',\n",
    "'Exchange',\n",
    "'Exclude_member',\n",
    "'Excreting',\n",
    "'Execution',\n",
    "'Expansion',\n",
    "'Expectation',\n",
    "'Expected_location_of_person',\n",
    "'Expensiveness',\n",
    "'Experience_bodily_harm',\n",
    "'Experiencer_focus',\n",
    "'Experiencer_obj',\n",
    "'Expertise',\n",
    "'Extreme_point',\n",
    "'Extreme_value',\n",
    "'Facial_expression',\n",
    "'Fairness_evaluation',\n",
    "'Fall_asleep',\n",
    "'Fame',\n",
    "'Familiarity',\n",
    "'Fear',\n",
    "'Fields',\n",
    "'Filling',\n",
    "'Finish_competition',\n",
    "'Finish_game',\n",
    "'Firing',\n",
    "'Fluidic_motion',\n",
    "'Food',\n",
    "'Foreign_or_domestic_country',\n",
    "'Forming_relationships',\n",
    "'Frequency',\n",
    "'Friendly_or_hostile',\n",
    "'Frugality',\n",
    "'Fullness',\n",
    "'Gesture',\n",
    "'Get_a_job',\n",
    "'Getting',\n",
    "'Give_impression',\n",
    "'Giving_birth',\n",
    "'Gizmo',\n",
    "'Gradable_artistic_quality',\n",
    "'Gradable_attributes',\n",
    "'Gradable_proximity',\n",
    "'Grasp',\n",
    "'Grinding',\n",
    "'Grooming',\n",
    "'Ground_up',\n",
    "'Guest_and_host',\n",
    "'Guilt_or_innocence',\n",
    "'Hair_configuration',\n",
    "'Having_or_lacking_access',\n",
    "'Health_response',\n",
    "'Hearsay',\n",
    "'Hit_or_miss',\n",
    "'Hostile_encounter',\n",
    "'Identicality',\n",
    "'Immobilization',\n",
    "'Impact',\n",
    "'Import_export_scenario',\n",
    "'Imprisonment',\n",
    "'Improvement_or_decline',\n",
    "'Indigenous_origin',\n",
    "'Information',\n",
    "'Information_display',\n",
    "'Ingest_substance',\n",
    "'Ingestion',\n",
    "'Inhibit_movement',\n",
    "'Interior_profile_relation',\n",
    "'Intoxicants',\n",
    "'Intoxication',\n",
    "'Judgment',\n",
    "'Judgment_communication',\n",
    "'Judgment_direct_address',\n",
    "'Judgment_of_intensity',\n",
    "'Killing',\n",
    "'Kinship',\n",
    "'Law_enforcement_agency',\n",
    "'Leadership',\n",
    "'Legality',\n",
    "'Level_of_force_exertion',\n",
    "'Level_of_force_resistance',\n",
    "'Level_of_light',\n",
    "'Light_movement',\n",
    "'Likelihood',\n",
    "'Locale_by_characteristic_entity',\n",
    "'Locale_by_event',\n",
    "'Locale_by_use',\n",
    "'Location_in_time',\n",
    "'Location_of_light',\n",
    "'Location_on_path',\n",
    "'Locative_relation',\n",
    "'Locative_scenario',\n",
    "'Luck',\n",
    "'Make_noise',\n",
    "'Making_faces',\n",
    "'Manipulate_into_doing',\n",
    "'Manipulate_into_shape',\n",
    "'Manipulation',\n",
    "'Manufacturing',\n",
    "'Mass_motion',\n",
    "'Measurable_attributes',\n",
    "'Measure_area',\n",
    "'Measure_by_action',\n",
    "'Measure_duration',\n",
    "'Measure_linear_extent',\n",
    "'Measure_mass',\n",
    "'Measure_scenario',\n",
    "'Measure_volume',\n",
    "'Medical_conditions',\n",
    "'Medical_instruments',\n",
    "'Medical_interaction_scenario',\n",
    "'Medical_intervention',\n",
    "'Medical_professionals',\n",
    "'Medical_specialties',\n",
    "'Member_of_military',\n",
    "'Mental_property',\n",
    "'Mental_stimulus_exp_focus',\n",
    "'Mental_stimulus_stimulus_focus',\n",
    "'Military',\n",
    "'Morality_evaluation',\n",
    "'Motion',\n",
    "'Motion_directional',\n",
    "'Motion_noise',\n",
    "'Moving_in_place',\n",
    "'Name_conferral',\n",
    "'Natural_features',\n",
    "'Negation',\n",
    "'Noise_makers',\n",
    "'Non-commutative_process',\n",
    "'Non-commutative_statement',\n",
    "'Non-gradable_proximity',\n",
    "'Obviousness',\n",
    "'Offenses',\n",
    "'Omen',\n",
    "'Ontogeny',\n",
    "'Openness',\n",
    "'Operate_vehicle',\n",
    "'Operational_testing',\n",
    "'Ordinal_numbers',\n",
    "'Organization',\n",
    "'Origin',\n",
    "'Others_situation_as_stimulus',\n",
    "'Part_inner_outer',\n",
    "'Part_ordered_segments',\n",
    "'Part_orientational',\n",
    "'Part_piece',\n",
    "'Part_whole',\n",
    "'Path_shape',\n",
    "'Path_traveled',\n",
    "'People',\n",
    "'Perception',\n",
    "'Performers_and_roles',\n",
    "'Personal_relationship',\n",
    "'Personal_success',\n",
    "'Piracy',\n",
    "'Placing',\n",
    "'Planting',\n",
    "'Political_actions',\n",
    "'Popularity',\n",
    "'Possession',\n",
    "'Possibility',\n",
    "'Practice',\n",
    "'Praiseworthiness',\n",
    "'Prank',\n",
    "'Precipitation',\n",
    "'Predicting',\n",
    "'Preference',\n",
    "'Presence',\n",
    "'Prevent_or_allow_possession',\n",
    "'Preventing_or_letting',\n",
    "'Probability',\n",
    "'Process',\n",
    "'Product_development_scenario',\n",
    "'Product_line',\n",
    "'Progression',\n",
    "'Prohibiting_or_licensing',\n",
    "'Project',\n",
    "'Proliferating_in_number',\n",
    "'Prominence',\n",
    "'Proportion',\n",
    "'Protecting',\n",
    "'Protest',\n",
    "'Provide_lodging',\n",
    "'Punctual_perception',\n",
    "'Purpose',\n",
    "'Quantity',\n",
    "'Quarreling',\n",
    "'Questioning',\n",
    "'Quitting',\n",
    "'Range',\n",
    "'Rape',\n",
    "'Ratification',\n",
    "'Reading_activity',\n",
    "'Reason',\n",
    "'Rebellion',\n",
    "'Receiving',\n",
    "'Records',\n",
    "'Recovery',\n",
    "'Redirecting',\n",
    "'Reforming_a_system',\n",
    "'Regard',\n",
    "'Relation',\n",
    "'Releasing',\n",
    "'Reliance',\n",
    "'Religious_belief',\n",
    "'Remainder',\n",
    "'Remembering_experience',\n",
    "'Removing',\n",
    "'Repayment',\n",
    "'Repel',\n",
    "'Replacing',\n",
    "'Representative',\n",
    "'Request',\n",
    "'Rescuing',\n",
    "'Research',\n",
    "'Residence',\n",
    "'Response',\n",
    "'Result_of_attempt_scenario',\n",
    "'Resurrection',\n",
    "'Reveal_secret',\n",
    "'Revenge',\n",
    "'Revolution',\n",
    "'Rewards_and_punishments',\n",
    "'Risk_scenario',\n",
    "'Robbery',\n",
    "'Rotting',\n",
    "'Run_risk',\n",
    "'Sacrificing_for',\n",
    "'Scarcity',\n",
    "'Scouring',\n",
    "'Scrutiny',\n",
    "'Secrecy_status',\n",
    "'Seeking',\n",
    "'Separating',\n",
    "'Setting_fire',\n",
    "'Severity_of_offense',\n",
    "'Sex',\n",
    "'Sharing',\n",
    "'Sharpness',\n",
    "'Shooting_scenario',\n",
    "'Shopping',\n",
    "'Silencing',\n",
    "'Similarity',\n",
    "'Size',\n",
    "'Sleep',\n",
    "'Smuggling',\n",
    "'Sociability',\n",
    "'Social_event',\n",
    "'Sole_instance',\n",
    "'Sounds',\n",
    "'Spatial_contact',\n",
    "'Specific_individual',\n",
    "'Speed_description',\n",
    "'Stage_of_progress',\n",
    "'Standing_by',\n",
    "'Stimulus_focus',\n",
    "'Stinginess',\n",
    "'Store',\n",
    "'Strictness',\n",
    "'Studying',\n",
    "'Subjective_influence',\n",
    "'Subordinates_and_superiors',\n",
    "'Substance',\n",
    "'Subversion',\n",
    "'Success_or_failure',\n",
    "'Suicide_attack',\n",
    "'Supply',\n",
    "'Supporting',\n",
    "'Surpassing',\n",
    "'Surrendering',\n",
    "'Surviving',\n",
    "'Suspicion',\n",
    "'Take_place_of',\n",
    "'Taking',\n",
    "'Tasting',\n",
    "'Team',\n",
    "'Telling',\n",
    "'Temperature',\n",
    "'Temporary_leave',\n",
    "'Terrorism',\n",
    "'Theft',\n",
    "'Thriving',\n",
    "'Thwarting',\n",
    "'Timespan',\n",
    "'Tolerating',\n",
    "'Topic',\n",
    "'Touring',\n",
    "'Toxic_substance',\n",
    "'Transfer',\n",
    "'Trap',\n",
    "'Travel',\n",
    "'Treating_and_mistreating',\n",
    "'Trendiness',\n",
    "'Trial',\n",
    "'Triggering',\n",
    "'Trust',\n",
    "'Type',\n",
    "'Unattributed_information',\n",
    "'Undergoing',\n",
    "'Undressing',\n",
    "'Unemployment_rate',\n",
    "'Use_firearm',\n",
    "'Used_up',\n",
    "'Using',\n",
    "'Vehicle',\n",
    "'Vehicle_landing',\n",
    "'Verdict',\n",
    "'Version_sequence',\n",
    "'Victim_operated_IED',\n",
    "'Violence',\n",
    "'Visiting',\n",
    "'Visiting_scenario',\n",
    "'Visitor_scenario',\n",
    "'Vocalizations',\n",
    "'Volubility',\n",
    "'Wagering',\n",
    "'Waiting',\n",
    "'Waking_up',\n",
    "'Want_suspect',\n",
    "'Wealthiness',\n",
    "'Weapon',\n",
    "'Wearing',\n",
    "'Weather',\n",
    "'Win_prize',\n",
    "'Within_distance',\n",
    "'Work',\n",
    "'Working_a_post'\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient('127.0.0.1', 27017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieves the database named framenet\n",
    "db = client.framenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates Collection object out of list ^^\n",
    "raw_data = db[\"raw_data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_data = db.p_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# do = 0\n",
    "for frame_name in frame_names_list:\n",
    "    f = fn.frame(frame_name)\n",
    "    print (frame_name)\n",
    "    LUs = list(f.lexUnit.keys())\n",
    "    for LU in LUs: # sometimes 0 LUs directly connected to a frame that has subframes; this is okay\n",
    "        LUText, pos = LU.split('.')\n",
    "        if pos not in ['v', 'a']: # wordnet has different pos names + we don't need to lemmatize the edge cases\n",
    "#             print (pos)\n",
    "            pos = 'n'\n",
    "        try:\n",
    "            for ex in fn.exemplars(LU):\n",
    "                exemplar = ex\n",
    "                text = exemplar.text\n",
    "                textWords = text.split()\n",
    "\n",
    "                # get main lexical unit that evokes frame as variable\n",
    "                lemmaL = [x for x in textWords if lemmatizer.lemmatize(x, pos=pos).lower() == LUText]\n",
    "                tempL = [lemmatizer.lemmatize(x) for x in textWords]\n",
    "                if len(lemmaL) > 0: # it should never be 0\n",
    "                    varText = lemmaL[0]\n",
    "                    varPos = textWords.index(varText)\n",
    "                    varTag = 'LU_' + frame_name\n",
    "                else:\n",
    "                    # it is 0 when what the exemplar does not match the LU (dataset is not perfect)\n",
    "                    # print out some things here if you want to check for yourself!\n",
    "                    pass\n",
    "                # get rest of variables\n",
    "                tags = exemplar.FE[0] # first of tuple is list of tags\n",
    "                for startIndex, endIndex, tag in tags:\n",
    "                    varText = text[startIndex:endIndex]\n",
    "                    # remove articles\n",
    "                    varTextL = varText.split(' ')\n",
    "                    varTextL = [x for x in varTextL if x != 'a' and x != 'A' and x != 'the' and x != 'The']\n",
    "                    varText = ' '.join(varTextL)\n",
    "                    # let's skip multi-word variables, since phrases are hard to make a vocabulary list for\n",
    "                    if ' ' in varText:\n",
    "                        continue\n",
    "\n",
    "                    if varText in textWords:\n",
    "                        varPos = textWords.index(varText)\n",
    "                        varTag = tag\n",
    "#                     else: happens when splitting by ' ' isn't enough... for example where 'â€”' is used\n",
    "\n",
    "        except RuntimeError as e:\n",
    "#             print(\"caught exception {}\".format(e))\n",
    "            continue\n",
    "        except Exception as e:\n",
    "#             catches: bad character range k-b at position... looks like '-' is the trigger\n",
    "#             print(\"caught other exception {}\".format(e))\n",
    "            continue\n",
    "\n",
    "#     do += 1\n",
    "#     if do > 0:    \n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm outside the tag loop\n",
      "sent: Ferris took the decision to abandon the aircraft , which crashed at 1205 at Oxborough , Norfolk \n",
      "tag: abandon.v\n",
      "sentenceIndex = 0\n",
      "tagIndex = -1\n",
      "text: Ferris took the decision to abandon the aircraft , which crashed at 1205 at Oxborough , Norfolk \n",
      "story: {\n",
      "\tframe: Ferris took the decision to  the aircraft , which crashed at 1205 at Oxborough , Norfolk \n",
      "\tvariablePosition: 6\n",
      "\tvariableTag: lu_Abandonment\n",
      "\tvariableText: abandon\n",
      "I'm inside the tag loop\n",
      "Ferris took the decision to abandon the aircraft , which crashed at 1205 at Oxborough , Norfolk \n",
      "abandon.v\n",
      "0\n",
      "0\n",
      "text: Ferris took the decision to abandon the aircraft , which crashed at 1205 at Oxborough , Norfolk \n",
      "story: {\n",
      "\tframe:  took the decision to abandon the aircraft , which crashed at 1205 at Oxborough , Norfolk \n",
      "\tvariablePosition: 6\n",
      "\tvariableTag: Self_mover\n",
      "\tvariableText: Ferris\n",
      "I'm inside the tag loop\n",
      "Ferris took the decision to abandon the aircraft , which crashed at 1205 at Oxborough , Norfolk \n",
      "abandon.v\n",
      "0\n",
      "1\n",
      "text: Ferris took the decision to abandon the aircraft , which crashed at 1205 at Oxborough , Norfolk \n",
      "story: {\n",
      "\tframe: Ferris took the decision to abandon  \n",
      "\tvariablePosition: 7\n",
      "\tvariableTag: Source\n",
      "\tvariableText: the aircraft , which crashed at 1205 at Oxborough , Norfolk\n",
      "I'm outside the tag loop\n",
      "sent: The count simply abandoned the small , expensive aircraft and led them to the car \n",
      "tag: leave.v\n",
      "sentenceIndex = 1\n",
      "tagIndex = -1\n",
      "text: The count simply abandoned the small , expensive aircraft and led them to the car \n",
      "story: {\n",
      "\tframe: The count simply abandoned the smallxpensive aircraft and led them to the car \n",
      "\tvariablePosition: 7\n",
      "\tvariableTag: lu_Abandonment\n",
      "\tvariableText:  , e\n",
      "I'm inside the tag loop\n",
      "The count simply abandoned the small , expensive aircraft and led them to the car \n",
      "leave.v\n",
      "1\n",
      "0\n",
      "text: The count simply abandoned the small , expensive aircraft and led them to the car \n",
      "story: {\n",
      "\tframe: The count simply aall , expensive aircraft and led them to the car \n",
      "\tvariablePosition: 7\n",
      "\tvariableTag: Affected\n",
      "\tvariableText: bandoned the sm\n",
      "I'm inside the tag loop\n",
      "The count simply abandoned the small , expensive aircraft and led them to the car \n",
      "leave.v\n",
      "1\n",
      "1\n",
      "text: The count simply abandoned the small , expensive aircraft and led them to the car \n",
      "story: {\n",
      "\tframe: The count simply abandoned the small , exaircraft and led them to the car \n",
      "\tvariablePosition: 7\n",
      "\tvariableTag: Effect\n",
      "\tvariableText: pensive \n",
      "I'm inside the tag loop\n",
      "The count simply abandoned the small , expensive aircraft and led them to the car \n",
      "leave.v\n",
      "1\n",
      "2\n",
      "text: The count simply abandoned the small , expensive aircraft and led them to the car \n",
      "story: {\n",
      "\tframe: The count simply abandoned the small , expensive a\n",
      "\tvariablePosition: 8\n",
      "\tvariableTag: Time\n",
      "\tvariableText: ircraft and led them to the car \n",
      "I'm outside the tag loop\n",
      "sent: The issue of abandoning Soviet bases was disputed in July 1955 at a Central Committee meeting in the Soviet Union \n",
      "tag: abandonment.n\n",
      "sentenceIndex = 2\n",
      "tagIndex = -1\n",
      "text: The issue of abandoning Soviet bases was disputed in July 1955 at a Central Committee meeting in the Soviet Union \n",
      "story: {\n",
      "\tframe: The issue of abandoning s was disputed in July 1955 at a Central Committee meeting in the Soviet Union \n",
      "\tvariablePosition: 5\n",
      "\tvariableTag: lu_Abandonment\n",
      "\tvariableText: Soviet base\n",
      "I'm inside the tag loop\n",
      "The issue of abandoning Soviet bases was disputed in July 1955 at a Central Committee meeting in the Soviet Union \n",
      "abandonment.n\n",
      "2\n",
      "0\n",
      "text: The issue of abandoning Soviet bases was disputed in July 1955 at a Central Committee meeting in the Soviet Union \n",
      "story: {\n",
      "\tframe: The issue of abandoning Soviet bases 1955 at a Central Committee meeting in the Soviet Union \n",
      "\tvariablePosition: 5\n",
      "\tvariableTag: Theme\n",
      "\tvariableText:  was disputed in July\n",
      "I'm outside the tag loop\n",
      "sent: Britain abandoned the Habbaniyah base in 1959 after Iraq left the Baghdad Pact in the wake of the previous summer 's revolution \n",
      "tag: abandoned.a\n",
      "sentenceIndex = 3\n",
      "tagIndex = -1\n",
      "text: Britain abandoned the Habbaniyah base in 1959 after Iraq left the Baghdad Pact in the wake of the previous summer 's revolution \n",
      "story: {\n",
      "\tframe: Britain abandoned the Habbaniyah base in 1959 after Iraq left the Baghdad Pact in the wake of the premer 's revolution \n",
      "\tvariablePosition: 19\n",
      "\tvariableTag: lu_Abandonment\n",
      "\tvariableText: vious sum\n",
      "I'm inside the tag loop\n",
      "Britain abandoned the Habbaniyah base in 1959 after Iraq left the Baghdad Pact in the wake of the previous summer 's revolution \n",
      "abandoned.a\n",
      "3\n",
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-d494e68a7e57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     68\u001b[0m                         \u001b[0mvariableTag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexemplars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msentenceIndex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"FE\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtagIndex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                         \u001b[0mvariableText\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetVariableText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentenceIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                         processed_data.insert_one({\n",
      "\u001b[0;32m<ipython-input-9-4af68ecd35dc>\u001b[0m in \u001b[0;36mgetVariableText\u001b[0;34m(sent, tag, sentenceIndex, tagIndex)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mstartIndex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexemplars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msentenceIndex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"FE\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtagIndex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mendIndex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexemplars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msentenceIndex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"FE\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtagIndex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstartIndex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mendIndex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/nltk/corpus/reader/framenet.py\u001b[0m in \u001b[0;36mexemplars\u001b[0;34m(self, luNamePattern, frame, fe, fe2)\u001b[0m\n\u001b[1;32m   2415\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mluNamePattern\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2416\u001b[0m                     \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2417\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mlu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mluNamePattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2418\u001b[0m                         \u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m                         \u001b[0mlusByFrame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/nltk/corpus/reader/framenet.py\u001b[0m in \u001b[0;36mlus\u001b[0;34m(self, name, frame)\u001b[0m\n\u001b[1;32m   2244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# match LUs, then restrict by frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2245\u001b[0m             result = PrettyList(\n\u001b[0;32m-> 2246\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mluID\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mluID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mluName\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlu_ids_and_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2247\u001b[0m             )\n\u001b[1;32m   2248\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/nltk/corpus/reader/framenet.py\u001b[0m in \u001b[0;36mlu_ids_and_names\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2282\u001b[0m         return {\n\u001b[1;32m   2283\u001b[0m             \u001b[0mluID\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mluinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2284\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mluID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mluinfo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lu_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2285\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mluinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_statuses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2286\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mluinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/nltk/corpus/reader/framenet.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2283\u001b[0m             \u001b[0mluID\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mluinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2284\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mluID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mluinfo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lu_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2285\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mluinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_statuses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2286\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mluinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2287\u001b[0m         }\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in copied_data:\n",
    "    f = fn.frame(i)\n",
    "    lexU = list(f.lexUnit.keys())\n",
    "    if len(lexU)>0:\n",
    "        \n",
    "        lazyIterator = fn.exemplars(lexU[0])\n",
    "        lazyIterator = lazyIterator.iterate_from(0)\n",
    "        \n",
    "        try:\n",
    "            while True:\n",
    "                \n",
    "                sentenceIndex = 0\n",
    "                #iterate through all lexical units\n",
    "                for tag in lexU:\n",
    "                    \n",
    "                    \n",
    "                    #gets sentences of each frame in raw_data\n",
    "                    #equivalent to fn.exemplars(lexU[0])[0]\n",
    "                    exemplar = next(lazyIterator)\n",
    "                    \n",
    "                    text = exemplar[\"text\"]\n",
    "                    sent = removePeriod(text)\n",
    "                    \n",
    "                    tagIndex = -1\n",
    "                    \n",
    "                    frameLU = getFrame(sent, tag, sentenceIndex, tagIndex)\n",
    "                    \n",
    "                    variablePositionLU = getVariablePosition(sent, tag, sentenceIndex, tagIndex)\n",
    "                    \n",
    "                    variableTagLU = \"lu_\"+ i\n",
    "                    \n",
    "                    variableTextLU = getVariableText(sent, tag, sentenceIndex, tagIndex)\n",
    "                    \n",
    "                    print(\"I'm outside the tag loop\")\n",
    "                    print(\"sent: \" + sent) \n",
    "                    print(\"tag: \" + tag)\n",
    "                    print(\"sentenceIndex = \" + str(sentenceIndex))\n",
    "                    print(\"tagIndex = \" + str(tagIndex))\n",
    "                    \n",
    "                    processed_data.insert_one({\n",
    "                            \"text\": sent, \n",
    "                            \"story\":{\n",
    "                                \"frame\":frameLU,\n",
    "                                \"variablePosition\": variablePositionLU ,\n",
    "                                \"variableTag\": variableTagLU,\n",
    "                                \"variableText\": variableTextLU }\n",
    "                         })\n",
    "                    \n",
    "                    print(\"text: \" + sent + \"\\n\" +\n",
    "                         \"story: {\\n\\tframe: \" + frameLU + \"\\n\\tvariablePosition: \" + str(variablePositionLU)\n",
    "                         + \"\\n\\tvariableTag: \"+ variableTagLU + \"\\n\\tvariableText: \"+ variableTextLU)\n",
    "                        \n",
    "                    #tagIndex is which tag/variable we're on\n",
    "                    tagIndex = 0\n",
    "                    tagInfoList = fn.exemplars(tag)[sentenceIndex][\"FE\"][0]\n",
    "                    while tagIndex < len(tagInfoList):\n",
    "                        \n",
    "                        print(\"I'm inside the tag loop\")\n",
    "                        print(sent) \n",
    "                        print(tag)\n",
    "                        print(str(sentenceIndex))\n",
    "                        print(str(tagIndex))\n",
    "  \n",
    "                        frame = getFrame(sent, tag, sentenceIndex, tagIndex)\n",
    "    \n",
    "                        variablePosition = getVariablePosition(sent, tag, sentenceIndex, tagIndex)\n",
    "        \n",
    "                        variableTag = fn.exemplars(tag)[sentenceIndex][\"FE\"][0][tagIndex][2]\n",
    "            \n",
    "                        variableText = getVariableText(sent, tag, sentenceIndex, tagIndex)\n",
    "\n",
    "                        processed_data.insert_one({\n",
    "                            \"text\": sent, \n",
    "                            \"story\":{\n",
    "                                \"frame\":frame,\n",
    "                                \"variablePosition\": variablePosition ,\n",
    "                                \"variableTag\": variableTag,\n",
    "                                \"variableText\": variableText }\n",
    "                        })\n",
    "                    \n",
    "                        print(\"text: \" + sent + \"\\n\" +\n",
    "                         \"story: {\\n\\tframe: \" + frame + \"\\n\\tvariablePosition: \" + str(variablePosition)\n",
    "                         + \"\\n\\tvariableTag: \"+ variableTag + \"\\n\\tvariableText: \"+ variableText)\n",
    "                        \n",
    "                        tagIndex+=1\n",
    "                    sentenceIndex+=1\n",
    "        except Exception as e:\n",
    "            print(\"sorry, data failed to process\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removePeriod(string):\n",
    "    i = string.find(\".\")\n",
    "    if (i >= 0):\n",
    "        string = string[0:i]\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVariableText(sent, tag, sentenceIndex, tagIndex):\n",
    "    \n",
    "    if (tagIndex < 0):\n",
    "        startIndex = fn.exemplars(tag)[sentenceIndex]['Target'][0][0]\n",
    "        endIndex = fn.exemplars(tag)[sentenceIndex]['Target'][0][1]\n",
    "        text = sent[startIndex:endIndex]\n",
    "        return text\n",
    "    else: \n",
    "        startIndex = fn.exemplars(tag)[sentenceIndex][\"FE\"][0][tagIndex][0]\n",
    "        endIndex = fn.exemplars(tag)[sentenceIndex][\"FE\"][0][tagIndex][1]\n",
    "        text = sent[startIndex:endIndex]\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFrame(sent, tag, sentenceIndex, tagIndex):\n",
    "    if (tagIndex < 0):\n",
    "        startIndex = fn.exemplars(tag)[sentenceIndex]['Target'][0][0]\n",
    "        endIndex = fn.exemplars(tag)[sentenceIndex]['Target'][0][1]\n",
    "        text = sent[:startIndex]+sent[endIndex:]\n",
    "        return text\n",
    "    else:\n",
    "        startIndex = fn.exemplars(tag)[sentenceIndex][\"FE\"][0][tagIndex][0]\n",
    "        endIndex = fn.exemplars(tag)[sentenceIndex][\"FE\"][0][tagIndex][1]\n",
    "        text = sent[:startIndex]+sent[endIndex:]\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method was created to find the WORD index by counting the number of spaces\n",
    "def getVariablePosition(sent, tag, sentenceIndex, tagIndex):\n",
    "    countSpaces = 0\n",
    "    startIndex = 0\n",
    "    if (tagIndex <= 0):\n",
    "        startIndex = fn.exemplars(tag)[sentenceIndex]['Target'][0][0]\n",
    "    else:\n",
    "        startIndex = fn.exemplars(tag)[sentenceIndex]['FE'][0][tagIndex][0]\n",
    "        \n",
    "    text = sent\n",
    "    while(len(text)>0 and text.index(\" \") >= 0 and text.index(\" \") <= startIndex):\n",
    "        \n",
    "        spaceIndex = text.index(\" \")\n",
    "        if (not isPunctuation(text, spaceIndex-1)):\n",
    "            countSpaces+=1\n",
    "            \n",
    "        currLen = len(text)\n",
    "        text = text[spaceIndex+1: ]\n",
    "        nextLen = len(text)\n",
    "        \n",
    "        lenLost = currLen - nextLen\n",
    "        startIndex -= lenLost\n",
    "    countSpaces += 1\n",
    "    return countSpaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isPunctuation(sent, index):\n",
    "    if (len(sent) > index and index >= 0):\n",
    "        if (sent[index:index+1] == \",\" or sent[index:index+1] == \"?\" or\n",
    "            sent[index:index+1] == \"!\" or sent[index:index+1] ==\".\" or \n",
    "            sent[index:index+1] ==\":\" or sent[index:index+1] ==\";\"):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = processed_data.find({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in x:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  documents deleted.\n"
     ]
    }
   ],
   "source": [
    "#to clear the processed_data collection\n",
    "x = processed_data.delete_many({})\n",
    "print(x.deleted_count, \" documents deleted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The count simply abandoned  and led them to the car \n",
      "the small , expensive aircraft\n",
      "Source\n",
      "5\n",
      "27\n",
      "57\n"
     ]
    }
   ],
   "source": [
    "sent = 'The count simply abandoned the small , expensive aircraft and led them to the car '\n",
    "tag = \"abandon.v\"\n",
    "sentenceIndex = 1\n",
    "tagIndex = 1\n",
    "print(getFrame(sent, tag, sentenceIndex, tagIndex))\n",
    "print(getVariableText(sent, tag, sentenceIndex, tagIndex))\n",
    "print(fn.exemplars(tag)[sentenceIndex][\"FE\"][0][tagIndex][2])\n",
    "print(getVariablePosition(sent, tag, sentenceIndex, tagIndex))\n",
    "startInd = fn.exemplars(tag)[sentenceIndex][\"FE\"][0][tagIndex][0]\n",
    "print(startInd)\n",
    "endInd = fn.exemplars(tag)[sentenceIndex][\"FE\"][0][tagIndex][1]\n",
    "print(endInd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
